from google.colab import drive
drive.mount("/content/drive")
import pandas as pd
import numpy as np
import tensorflow as tf
import tensorflow_hub as hub

data=pd.read_csv('/content/drive/MyDrive/imdb_movies.csv')
movies = data[['names', 'date_x', 'score', 'genre', 'overview', 'crew', 'orig_lang' ]]

# Define the function to create 'tags'
def create_tags(row):
    tags = []
    tags.append(str(row['genre']))
    tags.append(str(row['overview']))
    tags.append(str(row['crew']))
    # Exclude 'date_x' and 'score' as they are numerical
    return " ".join(tags)

# Apply the function to create a new 'tags' column
movies['tags'] = movies.apply(create_tags, axis=1)

# Lowercase the text and remove punctuation
movies['tags'] = movies['tags'].str.lower().str.replace('[^\w\s]', '', regex=True)

# Remove rows with NaN 'tags' and convert 'tags' to string
movies = movies.dropna(subset=['tags']).reset_index(drop=True)
movies['tags'] = movies['tags'].astype(str)

import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer

stop_words = set(stopwords.words('english'))
ps = PorterStemmer()

def preprocess_text(text):
    # Tokenize
    words = text.split()
    # Remove stop words and stem
    words = [ps.stem(word) for word in words if word not in stop_words]
    # Rejoin words
    return ' '.join(words)

movies['tags'] = movies['tags'].apply(preprocess_text)

!pip install torch==1.13.1
!pip install -q sentence-transformers

from sentence_transformers import SentenceTransformer

# Load the Sentence-BERT model
model = SentenceTransformer('all-MiniLM-L6-v2')

# Compute embeddings for all tags at once
tags_list = movies['tags'].tolist()
embeddings = model.encode(tags_list, convert_to_numpy=True, show_progress_bar=True)

print("Embeddings shape:", embeddings.shape)

# One-hot encode 'orig_lang'
orig_lang_encoded = pd.get_dummies(movies['orig_lang'], prefix='lang')

# Convert to NumPy array
orig_lang_array = orig_lang_encoded.values

# Combine text embeddings with 'orig_lang' one-hot encodings
embeddings_combined = np.hstack((embeddings, orig_lang_array))

print("Combined Embeddings shape:", embeddings_combined.shape)

# Compute the cosine similarity matrix
from sklearn.metrics.pairwise import cosine_similarity

cosine_sim_matrix = cosine_similarity(embeddings_combined)

print("Cosine similarity matrix shape:", cosine_sim_matrix.shape)

def recommend_movies_by_index(idx, top_n=5):
    sim_scores = list(enumerate(cosine_sim_matrix[idx]))
    sim_scores = [(i, float(score)) for i, score in sim_scores]
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:top_n+1]
    movie_indices = [i[0] for i in sim_scores]
    return movies.iloc[movie_indices]

# Test the recommendation function
name = 'Inception'
sample_idx = movies.index[movies['names'] == name][0]
recommendations = recommend_movies_by_index(sample_idx, top_n=5)
print("Movies similar to", name, ":\n", recommendations['names'].values)

def evaluate_model(movies, top_n=5):
    precision_list = []
    recall_list = []

    for idx, row in movies.iterrows():
        actual_genres = set(str(row['genre']).split(', '))
        recs = recommend_movies_by_index(idx, top_n=top_n)
        rec_genres = []

        for _, rec_row in recs.iterrows():
            genre_info = str(rec_row['genre'])
            rec_genres.extend(genre_info.split(', '))

        rec_genres = set(rec_genres)
        true_positives = actual_genres.intersection(rec_genres)
        precision = len(true_positives) / len(rec_genres) if rec_genres else 0
        recall = len(true_positives) / len(actual_genres) if actual_genres else 0

        precision_list.append(precision)
        recall_list.append(recall)

    avg_precision = np.mean(precision_list)
    avg_recall = np.mean(recall_list)

    print(f'Average Precision: {avg_precision:.4f}')
    print(f'Average Recall: {avg_recall:.4f}')

# Run the evaluation function
evaluate_model(movies, top_n=5)
